{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc_entity\n",
    "ESTABELECE RELAÇÕES ENTRE DOCUMENTOS E ENTIDADES NA BASE DE DADOS NO MYSQL. TRABALHAMOS COM O ACERVO **ANTONIO AZEREDO DA SILVEIRA, MINISTÉRIO DAS RELAÇÕES EXTERIORES**.  \n",
    "\n",
    "AS ENTIDADES A SEREM TRABALHADAS SÃO:\n",
    "* PAÍSES\n",
    "* PESSOAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#import pymysql\n",
    "import getpass\n",
    "#from sshtunnel import SSHTunnelForwarder\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import csv\n",
    "import xlrd\n",
    "import xlwt\n",
    "\n",
    "import getpass\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pymysql\n",
    "\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from collections import OrderedDict, Counter\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Sobre leitura de arquivos xls\n",
    "Links importantes:\n",
    "https://www.sitepoint.com/using-python-parse-spreadsheet-data/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "cria tabelas de entidades.\n",
    "nota: é apenas um template para código a ser criado\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    cur.execute(\"DROP TABLE IF EXISTS person_doc\")\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS person_doc \n",
    "               (person_id INT(11), doc_id VARCHAR(31), person_count BIGINT(21)\n",
    "               DEFAULT NULL)\n",
    "               ENGINE=MyISAM DEFAULT CHARSET='utf8';''')\n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS country_doc\")\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS country_doc \n",
    "               (country_id VARBINARY(11), doc_id VARCHAR(31), person_count INT(11)\n",
    "               DEFAULT NULL)\n",
    "               ENGINE=MyISAM DEFAULT CHARSET='utf8';''')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especifica qual sistema operacional está sendo usado. Renato = Linux ; Marcelo = nt (Windows) e define variáveis a partir disso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    ssh_priv_key = 'C:/Users/marcelo.ribeiro/Dropbox/A-Marcelo/Educação-Trabalho/2016-CPDOC/Remoto/marcelo_priv_rsa'\n",
    "    ssh_user='marcelobribeiro'\n",
    "    sql_user='marcelobribeiro'\n",
    "    path_inputs = \"C:/Users/marcelo.ribeiro/Dropbox/A-Marcelo/Educação-Trabalho/2016-CPDOC/Azeredo Papers/Processamento/text-learning-tools/inputs/\"\n",
    "    #path_inputs = \"C:/Users/MARCELO/Dropbox/A-Marcelo/Educação-Trabalho/2016-CPDOC/Azeredo Papers/Processamento/text-learning-tools/inputs/\"\n",
    "    path_outputs = \"C:/Users/marcelo.ribeiro/Dropbox/A-Marcelo/Educação-Trabalho/2016-CPDOC/Azeredo Papers/Processamento/text-learning-tools/outputs/\"\n",
    "else:\n",
    "    ssh_priv_key = '/home/rsouza/.ssh/id_rsa'\n",
    "    ssh_user='rsouza'\n",
    "    sql_user='rsouza'\n",
    "    path_inputs = \"/home/rsouza/Documentos/text-learning-tools/inputs/\"\n",
    "    path_outputs = \"/home/rsouza/Documentos/text-learning-tools/outputs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captura lista de nomes da base Accessus/CPDOC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abre arquivo XLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** file size (1367936) not 512 + multiple of sector size (512)\n"
     ]
    }
   ],
   "source": [
    "workbook = xlrd.open_workbook(path_inputs+'PESSOAS-do-Accessus.xls', on_demand = True)\n",
    "\n",
    "#worksheet = workbook.sheet_by_index(0)\n",
    "worksheet = workbook.sheet_by_name('Rel_DescritorEleito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strip_accents(s):\n",
    "   return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                  if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retira termos obtidos da lista de nomes, obtida em teste preliminar, que não são pessoas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_persons_list = ['manifestações', 'manobras', 'mão de obra', 'marxismo', 'materialismo', 'medicina', 'medidas', 'meeiros', 'meio', 'mercado', \n",
    " 'mercantilismo', 'messianismo', 'metrologia', 'ministério', 'missão', 'mobilidade', 'mobilização', 'modelo', 'monarquia', \n",
    " 'monopólio', 'mortalidade', 'movimento', 'mudança', 'municípios', 'nação', 'nacionalismo', 'negros']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpdoc_names_list = {}\n",
    "\n",
    "for line in range(worksheet.nrows):\n",
    "    breakpoint = 0\n",
    "    var_names = []\n",
    "    number_name = str(worksheet.cell(line, 0).value)\n",
    "    check_number = re.search('^\\d',number_name)\n",
    "    if check_number is not None:\n",
    "        if line == worksheet.nrows-1: break\n",
    "        fullname = str(worksheet.cell(line, 1).value)\n",
    "        fullname = str.lower(fullname)\n",
    "        for not_person in not_persons_list:\n",
    "            if not_person in fullname: breakpoint = 1\n",
    "        if breakpoint == 1: continue\n",
    "        fullname_strip_accent = strip_accents(fullname)\n",
    "        fullname_strip_abrev = re.sub('(\\w\\. ){0,4}', r'', fullname)\n",
    "        fullname_strip_both = strip_accents(fullname_strip_abrev)\n",
    "        var_names.append(fullname)\n",
    "        if fullname_strip_accent != fullname: var_names.append(fullname_strip_accent)\n",
    "        if fullname_strip_abrev  != fullname: var_names.append(fullname_strip_abrev)\n",
    "        if fullname_strip_both   != fullname_strip_abrev and fullname_strip_both != fullname_strip_accent: \n",
    "            var_names.append(fullname_strip_both)\n",
    "        cpdoc_names_list[fullname] = var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adelmo lodi',\n",
       " 'ademar alegria',\n",
       " 'ademar braga',\n",
       " 'ademar de barros',\n",
       " 'ademar de barros filho',\n",
       " 'ademar de faria',\n",
       " 'ademar de melo ',\n",
       " 'ademar de queiroz',\n",
       " 'ademar galvão',\n",
       " 'ademar gutierrez']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(cpdoc_names_list)[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captura lista de nomes da base History-Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "texts = []\n",
    "frus_names_list = {}\n",
    "\n",
    "#pass_sshkey = getpass.getpass()\n",
    "pass_mysql = getpass.getpass()\n",
    "conn = pymysql.connect(host='history-lab.org', \n",
    "                       user='de_reader',\n",
    "                       passwd=pass_mysql,\n",
    "                       db='declassification_frus',\n",
    "                       use_unicode=True, \n",
    "                       charset=\"utf8\")\n",
    "cur = conn.cursor()\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "insere dados na base mysql\n",
    "captura documentos da tabela docs, transfere para a tabela topic-doc e insere dados de tópicos\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "cur.execute(\"SELECT id, name FROM persons\")\n",
    "data = cur.fetchall()\n",
    "\n",
    "for row in data:\n",
    "    if row is None: break\n",
    "    var_names = []\n",
    "    count += 1 # for break event\n",
    "    fullname =  row[1]\n",
    "    fullname = str.lower(fullname)\n",
    "    fullname = re.sub('(.*), (.*)', r'\\2 \\1', fullname)\n",
    "    fullname = re.sub('(.*)\\(.*\\)\\s?(.*)', r'\\1\\2', fullname)\n",
    "    fullname = re.sub('- ', '-', fullname)\n",
    "    fullname_strip_accent = strip_accents(fullname)\n",
    "    fullname_strip_abrev = re.sub('(\\w\\. ){0,4}', r'', fullname)\n",
    "    fullname_strip_both = strip_accents(fullname_strip_abrev)\n",
    "    var_names.append(fullname)\n",
    "    if fullname_strip_accent != fullname: var_names.append(fullname_strip_accent)\n",
    "    if fullname_strip_abrev  != fullname: var_names.append(fullname_strip_abrev)\n",
    "    if fullname_strip_both   != fullname_strip_abrev and fullname_strip_both != fullname_strip_accent: \n",
    "        var_names.append(fullname_strip_both)\n",
    "    frus_names_list[fullname] = var_names    \n",
    "    #if count == 10: break #amostra de apenas x linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16284"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frus_names_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cria lista de nomes duplicados e remove das outras listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "duplicate_names_list = {}\n",
    "for name, values in cpdoc_names_list.items():\n",
    "    for alt_name in values:\n",
    "        if alt_name in frus_names_list:\n",
    "            duplicate_names_list[name] = cpdoc_names_list[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove das outras listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in duplicate_names_list:\n",
    "    cpdoc_names_list.pop(name, None)\n",
    "    frus_names_list.pop(name, None)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Captura textos da base CPDOC_AS do mysql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n",
      "········\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "texts = ''\n",
    "\n",
    "pass_sshkey = getpass.getpass()\n",
    "pass_mysql = getpass.getpass()\n",
    "with SSHTunnelForwarder(('200.20.164.147', 22),\n",
    "                        ssh_private_key=ssh_priv_key,\n",
    "                        ssh_private_key_password=pass_sshkey,\n",
    "                        ssh_username=ssh_user,\n",
    "                        remote_bind_address=('127.0.0.1', 3306)) as server:\n",
    "    \n",
    "    conn = pymysql.connect(host='localhost', \n",
    "                           port=server.local_bind_port, \n",
    "                           user=sql_user,\n",
    "                           passwd=pass_mysql,\n",
    "                           db='CPDOC_AS',\n",
    "                           use_unicode=True, \n",
    "                           charset=\"utf8\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    cur.execute(\"SELECT id,body FROM CPDOC_AS.docs\")\n",
    "    data = cur.fetchall()\n",
    "    \n",
    "    for row in data:\n",
    "        if row is None: break\n",
    "        count += 1 # for break event\n",
    "        text =  row[1]\n",
    "        texts += '\\r\\n'+ text\n",
    "        #if count == 10: break #amostra de apenas x linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faz mineração de dados: checa a existência de cada nome das listas em todo o corpus. Cria novas listas com os nomes checados.\n",
    "OBS: Essa primeira checagem captura o máximo possível de nomes, pois busca tanto por nomes quanto sobrenomes. Será necessário fazer uma segunda checagem para verificar se o nome exato ocorre, para evitar falsos positivos desnecessários e também para evitar ambiguidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(cpdoc_names_check, frus_names_check, duplicate_names_check) = {}, {}, {}\n",
    "collections_names_check = [cpdoc_names_check, frus_names_check, duplicate_names_check]\n",
    "collections_names_list = [cpdoc_names_list, frus_names_list, duplicate_names_list]\n",
    "for names_list in collections_names_list:\n",
    "    count = 0\n",
    "    percentil = int(len(names_list)/100)\n",
    "    collections_names_list_index = collections_names_list.index(names_list)\n",
    "    names_check = collections_names_check[collections_names_list_index]\n",
    "    for name,alt_names in names_list.items():\n",
    "        \n",
    "        count += 1\n",
    "        if count % percentil == 0: \n",
    "                clear_output()\n",
    "                print(int(count/percentil),'% done on list',collections_names_list.index(names_list))\n",
    "        \n",
    "        for i in alt_names:\n",
    "            if i in texts:\n",
    "                names_check[name] =  names_list[name]\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022\n",
      "922\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(cpdoc_names_check))\n",
    "print(len(frus_names_check))\n",
    "print(len(duplicate_names_check))\n",
    "#sorted(duplicate_names_check)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria lista de nomes que aparecem no corpus, mas estão fora das listas do accessus e do history-lab, ma. Nota: alguns nomes não estão identificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "azeredopapers_names_check = {}\n",
    "new_names = ['debernardi', 'alberto nogués', 'hans-dietrich genscher', 'allara', 'akasaka', 'sauvagnargues', 'andrei gromyko']\n",
    "for name in new_names: azeredopapers_names_check[name] = [name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in new_names: cpdoc_names_check.pop(name, None)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salva as 3 listas de nomes criadas (ou as recarrega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpdoc_names_check_file = path_outputs+'/corpus_entities_persons_list_cpdoc.pkl'\n",
    "frus_names_check_file = path_outputs+'/corpus_entities_persons_list_frus.pkl'\n",
    "duplicate_names_check_file = path_outputs+'/corpus_entities_persons_list_duplicate.pkl'\n",
    "azeredopapers_names_check_file = path_outputs+'/corpus_entities_persons_list_azeredopapers.pkl'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Ativar esta função apenas se precisar salvar novamente as listas de nomes checados no corpus\n",
    "pickle.dump(cpdoc_names_check, open(cpdoc_names_check_file, 'wb'))\n",
    "pickle.dump(frus_names_check, open(frus_names_check_file, 'wb'))\n",
    "pickle.dump(duplicate_names_check, open(duplicate_names_check_file, 'wb'))\n",
    "pickle.dump(azeredopapers_names_check, open(azeredopapers_names_check_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' caso queira carregar os arquivos '''\n",
    "cpdoc_names_check = pickle.load(open(cpdoc_names_check_file, 'rb'))\n",
    "frus_names_check = pickle.load(open(frus_names_check_file, 'rb'))\n",
    "duplicate_names_check = pickle.load(open(duplicate_names_check_file, 'rb'))\n",
    "azeredopapers_names_check = pickle.load(open(azeredopapers_names_check_file, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faz segunda checagem de nomes (duplicidades e ambiguidades), agora com a lista de nomes presentes no corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retira nomes ambíguos por não serem nomes compostos (sem sobrenome em geral), preservando exceções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akihito\n",
      "hirohito\n",
      "yoshihito\n"
     ]
    }
   ],
   "source": [
    "ambiguous_list = []\n",
    "exception_names = ['hirohito', 'yoshihito', 'akihito']\n",
    "for fullname in frus_names_check:\n",
    "    if \" \" not in fullname and fullname not in exception_names:\n",
    "        ambiguous_list.append(fullname)\n",
    "for fullname in ambiguous_list:\n",
    "    frus_names_check.pop(fullname, None)\n",
    "for fullname in frus_names_check:\n",
    "    if \" \" not in fullname:\n",
    "        print(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retira mais termos que não são pessoas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_names = ['moçambique', 'microfilmagem', 'marrocos', 'méxico', 'camboja', 'maçonaria', 'allara', 'niterói', 'nicarágua', 'misticismo', \n",
    " 'militarismo', 'legislação', 'burundi', 'música', 'maranhão', 'nova república', 'america do norte', 'mar territorial']\n",
    "for i in non_names:\n",
    "    cpdoc_names_check.pop(i, None)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista nomes que se tornam ambíguos ao retirar as abreviações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e. l. resende\n",
      "j. peres\n",
      "k. kato\n",
      "i. c. tupper\n",
      "h. s. owen\n",
      "a. faria\n",
      "j. h. russo\n",
      "j. e. brant\n",
      "b. goulart\n",
      "m. france\n",
      "m. bastos\n",
      "d. a. doran\n",
      "e. m. feinberg\n",
      "n. brandão\n",
      "c. h. adams\n",
      "d. gregory\n",
      "j. a. wright\n",
      "c. k. yen\n",
      "j. j. seabra\n",
      "a. azevedo\n",
      "f. chermont\n",
      "y. k. pao\n"
     ]
    }
   ],
   "source": [
    "for fullname in cpdoc_names_check:\n",
    "    fullname_strip_abrev = re.sub('(\\w\\. ){0,4}', r'', fullname)\n",
    "    if \" \" not in fullname_strip_abrev and fullname_strip_abrev != fullname:\n",
    "        print(fullname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrige nomes ambíguos, escritos de outra forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hirohito']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nomes duplicados \n",
    "duplicate_names_check['hirohito'] = frus_names_check['hirohito']\n",
    "cpdoc_names_check.pop('imperador hirohito', None) \n",
    "frus_names_check.pop('hirohito', None) \n",
    "\n",
    "#ocorrências incorretas\n",
    "#cpdoc_names_check.pop('albert probst', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica frequência de sobrenomes (retira primeiro nome e abreviações)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surnames_list = []\n",
    "for fullname in cpdoc_names_check:\n",
    "    fullname = re.sub('(\\w\\. ){0,4}', r'', fullname)\n",
    "    fullname = re.sub('( d[aeo] )', r' ', fullname)\n",
    "    fullname = re.sub('\\w+ (.*)', r'\\1', fullname)\n",
    "    fullname = fullname.split(' ')\n",
    "    for name in fullname:\n",
    "        surnames_list.append(name)\n",
    "for fullname in frus_names_check:\n",
    "    fullname = re.sub('(\\w\\. ){0,4}', r'', fullname)\n",
    "    fullname = re.sub('( d[aeo] )', r' ', fullname)\n",
    "    fullname = re.sub('\\w+ (.*)', r'\\1', fullname)\n",
    "    fullname = fullname.split(' ')\n",
    "    for name in fullname:\n",
    "        surnames_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['augusto',\n",
       " 'monte',\n",
       " 'lins',\n",
       " 'soares',\n",
       " 'resende',\n",
       " 'falcão',\n",
       " 'johnston',\n",
       " 'lira',\n",
       " 'pereira',\n",
       " 'leite']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checa a existência de nomes com sobrenomes ambíguos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for surname in surnames_list:\n",
    "    count = 0\n",
    "    for fullname in cpdoc_names_check:\n",
    "        if surname in fullname:\n",
    "            count += 1\n",
    "            if count > 1: print(fullname)\n",
    "            if surname == 'reis': break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sorted(cpdoc_names_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizando nomes (do cpdoc) em tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#name_prepositions_list = ['de', 'do'] # obsoleto, mas pode ser útil para outras funções\n",
    "\n",
    "cpdoc_series = pd.Series(cpdoc_names_check)\n",
    "cpdoc_data = pd.DataFrame(cpdoc_series, columns=['alt_names'])\n",
    "cpdoc_data.index.name = 'names'\n",
    "cpdoc_data['has_ambiguous_surname'], cpdoc_data['short_fullname'], cpdoc_data['short_surname'] = 'False', 'False', 'False'\n",
    "for row in cpdoc_data.itertuples():\n",
    "    \n",
    "    # check if fullname is too short\n",
    "    for alt_name in row[1]: \n",
    "        alt_name = re.sub('^(d[aeo]s? )', '', alt_name)\n",
    "        alt_name = re.sub('( d[aeo]s? )', ' ', alt_name)\n",
    "        if \" \" not in alt_name: cpdoc_data.ix[row[0], 'short_fullname'] = 'True'\n",
    "               \n",
    "    # check if fullname has a too ambiguous surname, or if fullname has a too short surname\n",
    "    fullname = row[0]\n",
    "    fullname = re.sub('\\w+ (.*)', r'\\1', fullname)\n",
    "    fullname = re.sub('(\\w\\. ){0,4}', '', fullname)\n",
    "    fullname = re.sub('^(d[aeo]s? )', '', fullname)\n",
    "    fullname = re.sub('( d[aeo]s? )', ' ', fullname)\n",
    "    fullname = fullname.split(' ')\n",
    "    for name in fullname:\n",
    "        count = 0\n",
    "        for key in cpdoc_names_check.keys():\n",
    "            if name in key:\n",
    "                count += 1\n",
    "        if count > 1: cpdoc_data.ix[row[0], 'has_ambiguous_surname'] = 'True'         \n",
    "        if len(name) < 5: cpdoc_data.ix[row[0], 'short_surname'] = 'True'\n",
    "\n",
    "    #if row[0] == 'abreu lima': break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alt_names</th>\n",
       "      <th>has_ambiguous_surname</th>\n",
       "      <th>short_fullname</th>\n",
       "      <th>short_surname</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a. azevedo</th>\n",
       "      <td>[a. azevedo, azevedo]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a. faria</th>\n",
       "      <td>[a. faria, faria]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a. i. de lima</th>\n",
       "      <td>[a. i. de lima, de lima]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a. j. peixoto de castro</th>\n",
       "      <td>[a. j. peixoto de castro, peixoto de castro]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abgar renault</th>\n",
       "      <td>[abgar renault]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abreu lima</th>\n",
       "      <td>[abreu lima]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adalberto de barros nunes</th>\n",
       "      <td>[adalberto de barros nunes]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adalberto pereira dos santos</th>\n",
       "      <td>[adalberto pereira dos santos]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adalberto sena</th>\n",
       "      <td>[adalberto sena]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ademar de barros</th>\n",
       "      <td>[ademar de barros]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ademar de barros filho</th>\n",
       "      <td>[ademar de barros filho]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adlai e. stevenson</th>\n",
       "      <td>[adlai e. stevenson, adlai stevenson]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adroaldo mesquita da costa</th>\n",
       "      <td>[adroaldo mesquita da costa]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adyr fiúza de castro</th>\n",
       "      <td>[adyr fiúza de castro, adyr fiuza de castro]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affonso massot</th>\n",
       "      <td>[affonso massot]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afonso arinos de melo franco</th>\n",
       "      <td>[afonso arinos de melo franco]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afonso pena</th>\n",
       "      <td>[afonso pena]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afrânio coutinho</th>\n",
       "      <td>[afrânio coutinho, afranio coutinho]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afrânio de oliveira</th>\n",
       "      <td>[afrânio de oliveira, afranio de oliveira]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afrânio nabuco</th>\n",
       "      <td>[afrânio nabuco, afranio nabuco]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 alt_names  \\\n",
       "names                                                                        \n",
       "a. azevedo                                           [a. azevedo, azevedo]   \n",
       "a. faria                                                 [a. faria, faria]   \n",
       "a. i. de lima                                     [a. i. de lima, de lima]   \n",
       "a. j. peixoto de castro       [a. j. peixoto de castro, peixoto de castro]   \n",
       "abgar renault                                              [abgar renault]   \n",
       "abreu lima                                                    [abreu lima]   \n",
       "adalberto de barros nunes                      [adalberto de barros nunes]   \n",
       "adalberto pereira dos santos                [adalberto pereira dos santos]   \n",
       "adalberto sena                                            [adalberto sena]   \n",
       "ademar de barros                                        [ademar de barros]   \n",
       "ademar de barros filho                            [ademar de barros filho]   \n",
       "adlai e. stevenson                   [adlai e. stevenson, adlai stevenson]   \n",
       "adroaldo mesquita da costa                    [adroaldo mesquita da costa]   \n",
       "adyr fiúza de castro          [adyr fiúza de castro, adyr fiuza de castro]   \n",
       "affonso massot                                            [affonso massot]   \n",
       "afonso arinos de melo franco                [afonso arinos de melo franco]   \n",
       "afonso pena                                                  [afonso pena]   \n",
       "afrânio coutinho                      [afrânio coutinho, afranio coutinho]   \n",
       "afrânio de oliveira             [afrânio de oliveira, afranio de oliveira]   \n",
       "afrânio nabuco                            [afrânio nabuco, afranio nabuco]   \n",
       "\n",
       "                             has_ambiguous_surname short_fullname  \\\n",
       "names                                                               \n",
       "a. azevedo                                    True           True   \n",
       "a. faria                                      True           True   \n",
       "a. i. de lima                                 True           True   \n",
       "a. j. peixoto de castro                       True          False   \n",
       "abgar renault                                False          False   \n",
       "abreu lima                                    True          False   \n",
       "adalberto de barros nunes                     True          False   \n",
       "adalberto pereira dos santos                  True          False   \n",
       "adalberto sena                               False          False   \n",
       "ademar de barros                              True          False   \n",
       "ademar de barros filho                        True          False   \n",
       "adlai e. stevenson                           False          False   \n",
       "adroaldo mesquita da costa                    True          False   \n",
       "adyr fiúza de castro                          True          False   \n",
       "affonso massot                               False          False   \n",
       "afonso arinos de melo franco                  True          False   \n",
       "afonso pena                                   True          False   \n",
       "afrânio coutinho                              True          False   \n",
       "afrânio de oliveira                           True          False   \n",
       "afrânio nabuco                                True          False   \n",
       "\n",
       "                             short_surname  \n",
       "names                                       \n",
       "a. azevedo                           False  \n",
       "a. faria                             False  \n",
       "a. i. de lima                         True  \n",
       "a. j. peixoto de castro              False  \n",
       "abgar renault                        False  \n",
       "abreu lima                            True  \n",
       "adalberto de barros nunes            False  \n",
       "adalberto pereira dos santos         False  \n",
       "adalberto sena                        True  \n",
       "ademar de barros                     False  \n",
       "ademar de barros filho               False  \n",
       "adlai e. stevenson                   False  \n",
       "adroaldo mesquita da costa           False  \n",
       "adyr fiúza de castro                 False  \n",
       "affonso massot                       False  \n",
       "afonso arinos de melo franco          True  \n",
       "afonso pena                           True  \n",
       "afrânio coutinho                     False  \n",
       "afrânio de oliveira                  False  \n",
       "afrânio nabuco                       False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdoc_data[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserção na base de dados"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#test\n",
    "text = \"a. azevedo falou, a. faria discordou, a. i. de lima acreditou, a. j. peixoto de castro removeu, abgar renault criticou.\"\n",
    "for row in cpdoc_data.itertuples():\n",
    "    person_id = count\n",
    "    name = row[0]\n",
    "    #print(name)    \n",
    "        \n",
    "    person_count = 0\n",
    "    if cpdoc_data.ix[row[0], 'has_ambiguous_surname'] == 'True' or cpdoc_data.ix[row[0], 'short_surname'] == 'True' or cpdoc_data.ix[row[0], 'short_fullname'] == 'True': \n",
    "        person_count = text.count(name)\n",
    "        if person_count != 0: print(person_count)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 % done\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "pass_sshkey = getpass.getpass()\n",
    "pass_mysql = getpass.getpass()\n",
    "with SSHTunnelForwarder(('200.20.164.147', 22),\n",
    "                        ssh_private_key=ssh_priv_key,\n",
    "                        ssh_private_key_password=pass_sshkey,\n",
    "                        ssh_username=ssh_user,\n",
    "                        remote_bind_address=('127.0.0.1', 3306)) as server:\n",
    "    \n",
    "    conn = pymysql.connect(host='localhost', \n",
    "                           port=server.local_bind_port, \n",
    "                           user=sql_user,\n",
    "                           passwd=pass_mysql,\n",
    "                           db='CPDOC_AS',\n",
    "                           use_unicode=True, \n",
    "                           charset=\"utf8\")\n",
    "    cur = conn.cursor()\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "    cur.execute(\"DROP TABLE IF EXISTS persons\")\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS persons\n",
    "               (id VARCHAR(128) PRIMARY KEY, person_name VARCHAR(128)\n",
    "               DEFAULT NULL)\n",
    "               ENGINE=MyISAM DEFAULT CHARSET='utf8';''')\n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS person_doc\")\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS person_doc\n",
    "               (person_id VARCHAR(128), doc_id VARCHAR(31), person_count SMALLINT(5)\n",
    "               DEFAULT NULL)\n",
    "               ENGINE=MyISAM DEFAULT CHARSET='utf8';''')\n",
    "    \n",
    "    cur.execute(\"SELECT * FROM CPDOC_AS.docs WHERE main_language = 'pt' AND (readability > 0.4 OR readability = -1) \")  \n",
    "    \n",
    "    text_data = cur.fetchall()\n",
    "    \n",
    "    numrows_df = len(cpdoc_data.index)\n",
    "    percentil = int(numrows_df/100)\n",
    "    \n",
    "    for row_name in cpdoc_data.itertuples():\n",
    "        person_id = count + 500000 # id do History-Lab termina em 116.000. Precisamos ter uma sequência de ID distante, tal como foi acordado entre Marcelo e Rohan\n",
    "        name = row_name[0]\n",
    "        alt_names = cpdoc_data.ix[row_name[0], 'alt_names']\n",
    "        \n",
    "        ### mede percentual de conclusão da tarefa ###\n",
    "        if count % 100 == 0: \n",
    "            clear_output()\n",
    "            print(int((count)/percentil),'% done')\n",
    "        \n",
    "        for row_text in text_data:\n",
    "            text = row_text[4]\n",
    "            doc_id = row_text[0]\n",
    "                        \n",
    "            person_count = 0\n",
    "            if cpdoc_data.ix[row_name[0], 'has_ambiguous_surname'] == 'True' or cpdoc_data.ix[row_name[0], 'short_surname'] == 'True' or cpdoc_data.ix[row_name[0], 'short_fullname'] == 'True': \n",
    "                person_count = text.count(name)\n",
    "            else: \n",
    "                for name in alt_names:\n",
    "                    person_subfreq = text.count(name)\n",
    "                    person_count += person_subfreq\n",
    "            if person_count > 0: \n",
    "                query = \"INSERT INTO person_doc VALUES (%s, %s, %s)\"\n",
    "                cur.execute(query, (person_id, doc_id, person_count))\n",
    "        \n",
    "        query = \"INSERT INTO persons VALUES (%s, %s)\"\n",
    "        cur.execute(query, (person_id, name))\n",
    "        \n",
    "        count += 1\n",
    "        #if count >= 100: break #amostra de apenas x linhas ~ 10%\n",
    "    \n",
    "    # acrescenta colunas presentes na base do History-Lab (default = nulo)\n",
    "    cur.execute(\"ALTER TABLE persons ADD birth_year INT(4)\")\n",
    "    cur.execute(\"ALTER TABLE persons ADD death_year INT(4)\")\n",
    "    cur.execute(\"ALTER TABLE persons ADD description MEDIUMTEXT\")\n",
    "    cur.execute(\"ALTER TABLE person_doc ADD date DATETIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise Exploratória de Dados"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#teste\n",
    "names_list_test = ['geisel', 'azeredo', 'ernesto', 'antonio']\n",
    "text_test1 = 'O ministro antonio azeredo assinou o tratado. Já o presidente ernesto geisel não concordou com azeredo'\n",
    "text_test2 = 'O ministro antonio azeredo é contra tecnologia nuclear. Já o presidente ernesto geisel defende acordo com alemanha ocidental'\n",
    "texts = text_test1 + '\\r\\n' + text_test2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#test\n",
    "count = 0\n",
    "for name in cpdoc_names_check:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    if count == 50: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['own', 'party', 'and', 'splitting', 'it', 'in', 'the', 'process', ';', 'mirabeau', 'prvsiding', 'over', 'an', 'attempt', 'at', 'legal', 'revolution', '.', 'bismarck', 'was', 'back', 'on', 'the', 'ancestral', 'estate', 'now', '.', 'restless', ',', 'he', 'read', 'voraciously', ':', 'shakespeare', 'and', 'byron', ',', 'louis', 'blanc', 'and', 'voltaire', ',', 'and', 'always', 'spinoza', '.', 'his', 'escapades', 'multiplied', '.', 'after', 'another', 'hrokcn', 'engagement', ',', 'bismarck', 'lcft', 'on', '&', 'journey', 'through', 'england', ',', 'france', ',', 'and', 'switzerland', '.', 'he', 'even', 'made', 'tentative', 'plans', 'to', 'serve', 'with', 'the', 'british', 'army', 'in']\n",
      "['represas', '.', 'desmentido', ',', 'como', 'vimos', ',', 'el', 'mismo', '-', 'dia', 'sicuiente', '.', 'el', 'optimismo', 'es', 'a', 'veces', 'un', 'fenomeno', 'muy', 'curioso', '.', ';--', 'el', 'patrono', 'literario', 'de', 'todos', 'los', 'optimistas', 'es', 'aquel', 'famoso', 'personaje', 'del', '\"', 'candido', '\"', 'de', 'voltaire', ',', 'el', 'doctor', 'pangloss', ',', 'quien', '-', 'en', 'medio', 'de', 'las', 'mas', 'terribles', 'catastrofes', '-', 'afirmaba', 'imperturbablemei', '-', 'u', 'te', 'que', '\"', 'todo', 'marcha', 'para', 'bien', 'en', 'el', 'mejor', 'de', 'los', 'mundos', 'posibles', '\".', ',', '25', ':', 'ser', 'optimista']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9308b566c6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtknzr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWordPunctTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtknzr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# texto com stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[1;31m#tokens = tknzr.tokenize(cleaned_texts) # texto sem stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[1;31m#print(tokens)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#query = 'azeredo'\n",
    "count = 0\n",
    "for name in cpdoc_names_check:\n",
    "    count += 1\n",
    "    query = name\n",
    "    tknzr = nltk.tokenize.WordPunctTokenizer()\n",
    "    tokens = tknzr.tokenize(texts) # texto com stopwords\n",
    "    #tokens = tknzr.tokenize(cleaned_texts) # texto sem stopwords\n",
    "    #print(tokens)\n",
    "    try:\n",
    "        print(tokens[tokens.index(name)-40 : tokens.index(name)+40])\n",
    "        tokens = tokens[tokens.index(name)+1:]\n",
    "        print(tokens[tokens.index(name)-40 : tokens.index(name)+40])\n",
    "    except: continue\n",
    "    if count == 50: break\n",
    "    #nltk_text = nltk.Text(tokens)\n",
    "    #nltk_text.concordance(query.lower(), width=60, lines=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nltk_text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#About chunk tags: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "sentence = \"O ministro antonio azeredo assinou o tratado. Já o presidente ernesto geisel não concordou com a atitude de azeredo\"\n",
    "sent1 = nltk.word_tokenize(sentence)\n",
    "sent2 = nltk.pos_tag(sent1)\n",
    "sent3 =  nltk.ne_chunk(sent2, binary=True)\n",
    "sent3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nltk_text.similar(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agradeço prezado; das relações; marcio muller; new bedford; relações\n",
      "exteriores; brazilian consulate; muller bueno; professor haroldo;\n",
      "souto 408; vieira souto; afetuoso abraço; amigo generosas; prezado\n",
      "amigo; para embaixador; embaixador azeredo; azeredo silveira\n"
     ]
    }
   ],
   "source": [
    "nltk_text.collocations(num=20, window_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocations are expressions of multiple words which commonly co-occur.\n",
    "Below we are using Pointwise Mutual Information.\n",
    "http://en.wikipedia.org/wiki/Pointwise_mutual_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agradeço prezado\n",
      "das relações\n",
      "marcio muller\n",
      "new bedford\n",
      "relações exteriores\n",
      "brazilian consulate\n",
      "muller bueno\n",
      "professor haroldo\n",
      "b rjo\n",
      "souto 408\n",
      "vieira souto\n",
      "afetuoso abraço\n",
      "amigo generosas\n",
      "do brasil\n",
      "prezado amigo\n",
      "telegrama no\n",
      "para embaixador\n",
      "pt afetuoso\n",
      "azeredo da\n",
      "embaixador azeredo\n",
      "da silveira\n",
      "rio gb\n",
      "t e\n",
      "azeredo silveira\n",
      "amigo pt\n",
      "de estado\n",
      "de novembro\n",
      "secretaria de\n",
      "15 de\n",
      ".. ..\n",
      "em de\n",
      "de de\n"
     ]
    }
   ],
   "source": [
    "max_items = 50\n",
    "freq_min_b = 2\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder2 = nltk.collocations.BigramCollocationFinder.from_words(nltk_text)\n",
    "finder2.apply_word_filter(lambda w: w in string.punctuation)\n",
    "finder2.apply_freq_filter(freq_min_b)\n",
    "for a, b in finder2.nbest(bigram_measures.pmi, max_items):\n",
    "    print (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marcio muller bueno\n",
      "agradeço prezado amigo\n",
      "prezado amigo generosas\n",
      "pt afetuoso abraço\n",
      "secretaria de estado\n",
      "15 de novembro\n",
      "azeredo da silveira\n",
      "amigo pt afetuoso\n",
      ".. .. ..\n"
     ]
    }
   ],
   "source": [
    "max_items = 50\n",
    "freq_min_t = 2\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "finder3 = nltk.collocations.TrigramCollocationFinder.from_words(nltk_text)\n",
    "finder3.apply_word_filter(lambda w: w in string.punctuation)\n",
    "finder3.apply_ngram_filter(lambda w1, w2, w3:  w1 in ['da', 'de', 'das'])\n",
    "finder3.apply_freq_filter(freq_min_t)\n",
    "for a, b, c in finder3.nbest(trigram_measures.pmi, max_items):\n",
    "    print (a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. ..\n",
      "pt afetuoso\n",
      "rio gb\n",
      "da silveira\n",
      "15 de\n",
      "afetuoso abraço\n",
      "agradeço prezado\n",
      "amigo generosas\n",
      "amigo pt\n",
      "azeredo da\n",
      "azeredo silveira\n",
      "b rjo\n",
      "brazilian consulate\n",
      "das relações\n",
      "de de\n",
      "de estado\n",
      "de novembro\n",
      "do brasil\n",
      "em de\n",
      "embaixador azeredo\n",
      "marcio muller\n",
      "muller bueno\n",
      "new bedford\n",
      "para embaixador\n",
      "prezado amigo\n",
      "professor haroldo\n",
      "relações exteriores\n",
      "secretaria de\n",
      "souto 408\n",
      "t e\n",
      "telegrama no\n",
      "vieira souto\n"
     ]
    }
   ],
   "source": [
    "for a, b in (finder2.above_score(bigram_measures.raw_freq,1.0 / len(list(nltk.bigrams(tokens))))):\n",
    "        print (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. .. ..\n",
      "15 de novembro\n",
      "agradeço prezado amigo\n",
      "amigo pt afetuoso\n",
      "azeredo da silveira\n",
      "marcio muller bueno\n",
      "prezado amigo generosas\n",
      "pt afetuoso abraço\n",
      "secretaria de estado\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in finder3.above_score(trigram_measures.raw_freq,1.0 / len(list(nltk.trigrams(tokens)))):\n",
    "        print (a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequência</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(.., .., .., ..)</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(., .., .., ..)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(agradeço, prezado, amigo, generosas)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(., .., ,, .)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(r, a, m, a)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(/, 1244, %, ãdãaam)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(_, ., ., -)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(mv, ,, ;, ()</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(e, horas, x, \"?)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1130, antonio, francisco, da)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(\",, \", ic, -)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(novembro, qg, rio, gb)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1, -, 45, ,)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(do, itamaraty, vg, do)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(abrasso, *, serjocosta, ')</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(,, ., _, ostensivo)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(aí, ', &amp;, \")</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(generosas, felicitacoes, pt, afetuoso)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(24, 29, 1659, r)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(exteriores, %, g, em)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sucesso, serah, do, itamaraty)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(), má, &lt;&gt;,, /)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(\", na, \", a)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(afetuoso, abrasso, *, serjocosta)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(nil, i, -, iq)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(gb, imito, agradeço, prezado)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(h, :), ©, 074)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(o, a, %, mfáhôa)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(armanoo, (, *, _)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(21, &lt;, egbrx, co)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2055, professor, haroldq, valadao)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(pt, afetuoso, abraco, silveira)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(moram, ., \", \")</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-, faz, /\", zm)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(/, w, /, .)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(,, 1, -, 45)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(-, gbip, co, gdp033)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sua, indicação, chefia, itamarati)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(!,, ', o, &lt;)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(riodejaneiro, olxdfm, palegre, ??)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Frequência\n",
       "Tokens                                             \n",
       "(.., .., .., ..)                                 13\n",
       "(., .., .., ..)                                   2\n",
       "(agradeço, prezado, amigo, generosas)             2\n",
       "(., .., ,, .)                                     2\n",
       "(r, a, m, a)                                      1\n",
       "(/, 1244, %, ãdãaam)                              1\n",
       "(_, ., ., -)                                      1\n",
       "(mv, ,, ;, ()                                     1\n",
       "(e, horas, x, \"?)                                 1\n",
       "(1130, antonio, francisco, da)                    1\n",
       "(\",, \", ic, -)                                    1\n",
       "(novembro, qg, rio, gb)                           1\n",
       "(1, -, 45, ,)                                     1\n",
       "(do, itamaraty, vg, do)                           1\n",
       "(abrasso, *, serjocosta, ')                       1\n",
       "(,, ., _, ostensivo)                              1\n",
       "(aí, ', &, \")                                     1\n",
       "(generosas, felicitacoes, pt, afetuoso)           1\n",
       "(24, 29, 1659, r)                                 1\n",
       "(exteriores, %, g, em)                            1\n",
       "(sucesso, serah, do, itamaraty)                   1\n",
       "(), má, <>,, /)                                   1\n",
       "(\", na, \", a)                                     1\n",
       "(afetuoso, abrasso, *, serjocosta)                1\n",
       "(nil, i, -, iq)                                   1\n",
       "(gb, imito, agradeço, prezado)                    1\n",
       "(h, :), ©, 074)                                   1\n",
       "(o, a, %, mfáhôa)                                 1\n",
       "(armanoo, (, *, _)                                1\n",
       "(21, <, egbrx, co)                                1\n",
       "(2055, professor, haroldq, valadao)               1\n",
       "(pt, afetuoso, abraco, silveira)                  1\n",
       "(moram, ., \", \")                                  1\n",
       "(-, faz, /\", zm)                                  1\n",
       "(/, w, /, .)                                      1\n",
       "(,, 1, -, 45)                                     1\n",
       "(-, gbip, co, gdp033)                             1\n",
       "(sua, indicação, chefia, itamarati)               1\n",
       "(!,, ', o, <)                                     1\n",
       "(riodejaneiro, olxdfm, palegre, ??)               1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4\n",
    "xgrams = ngrams(tokens, n)\n",
    "xgrams_counter = Counter(xgrams)\n",
    "series_xgrams_counter = pd.Series(data=xgrams_counter, index=xgrams_counter.keys())\n",
    "df_ngrams = pd.DataFrame(series_xgrams_counter, columns = ['Frequência'])\n",
    "df_ngrams = df_ngrams.sort_values(by='Frequência', ascending=False)\n",
    "df_ngrams.index.name = 'Tokens'\n",
    "df_ngrams[0:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RASCUNHOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inaugural' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-20cdf2ee20cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m cfd = nltk.ConditionalFreqDist(\n\u001b[1;32m      2\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[1;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minaugural\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minaugural\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'america'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'citizen'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inaugural' is not defined"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (target, fileid[:4])\n",
    "    for fileid in inaugural.fileids()\n",
    "    for w in inaugural.words(fileid)\n",
    "    for target in ['america', 'citizen']\n",
    "    if w.lower().startswith(target)) [1]\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ENTIDADE: PESSOA\n",
    "\n",
    "Alimenta a tabela person_doc, da nossa base no mysql, fazendo interseção de dados da tabela persons com a tabela docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n",
      "········\n",
      "azeredo text_id rb_1974.04.17_doc_I-66\n",
      "azeredo text_id onu_1974.03.12_doc_II-49\n",
      "azeredo text_id onu_1974.03.12_doc_V-2\n",
      "azeredo text_id be_1974.04.16_doc_VI-18\n",
      "azeredo text_id be_1977.06.01_doc_II-21\n",
      "azeredo text_id ag_1974.03.13_doc_III-7\n",
      "azeredo text_id ag_1973.11.20_doc_VI-75\n",
      "azeredo text_id d_1974.04.23_doc_XXXII-8\n",
      "azeredo text_id d_1974.03.26_doc_XXXII-32\n",
      "azeredo text_id d_1974.03.26_doc_XXII-9\n"
     ]
    }
   ],
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "alimenta a a tabela person_doc, da nossa base no mysql.\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "count = 0\n",
    "#percentil = int(len(cursor.rowcount/100)\n",
    "\n",
    "pass_sshkey = getpass.getpass()\n",
    "pass_mysql = getpass.getpass()\n",
    "with SSHTunnelForwarder(('200.20.164.147', 22),\n",
    "                        ssh_private_key = \"C:/Users/marcelo.ribeiro/Dropbox/A-Marcelo/Educação-Trabalho/2016-CPDOC/Remoto/marcelo_priv_rsa\",\n",
    "                        #ssh_private_key = '/home/rsouza/.ssh/id_rsa',\n",
    "                        ssh_private_key_password = pass_sshkey,\n",
    "                        ssh_username=\"marcelobribeiro\",\n",
    "                        #ssh_username=\"rsouza\",\n",
    "                        remote_bind_address=('127.0.0.1', 3306)) as server:\n",
    "    \n",
    "    conn = pymysql.connect(host='localhost', \n",
    "                           port=server.local_bind_port, \n",
    "                           user='marcelobribeiro', \n",
    "                           #user='rsouza',\n",
    "                           passwd=pass_mysql,\n",
    "                           db='CPDOC_AS',\n",
    "                           use_unicode=True, \n",
    "                           charset=\"utf8\")\n",
    "    cur = conn.cursor()\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    insere dados na base mysql\n",
    "    captura documentos da tabela docs, transfere para a tabela topic-doc e insere dados de tópicos\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS person_doc\")\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS person_doc \n",
    "               (person_id INT(11), doc_id VARCHAR(31), person_count BIGINT(21)\n",
    "               DEFAULT NULL)\n",
    "               ENGINE=MyISAM DEFAULT CHARSET='utf8';''')\n",
    "\n",
    "    cur.execute(\"SELECT id,body FROM CPDOC_AS.docs\")\n",
    "    data = cur.fetchall()\n",
    "    for row in data:\n",
    "        count += 1 # for break event\n",
    "        if row is None: break\n",
    "        text_id = row[0]\n",
    "        text =  row[1]\n",
    "        #text = text.split()\n",
    "        doc_id = row[0]\n",
    "        for name in names_list_test:\n",
    "            person_id = 1\n",
    "            person_count = text.count(name)\n",
    "            #query = \"INSERT INTO person_doc VALUES (%s, %s, %s)\"\n",
    "            #cur.execute(query, (person_id, doc_id, person_count))\n",
    "        print(name, 'text_id', text_id)\n",
    "        #print(doc_id, topic_id, topic_score)   \n",
    "        #cur.execute(\"ALTER TABLE person_doc ORDER BY doc_id ASC, person_count DESC\")\n",
    "        \n",
    "        if count == 2: break #amostra de apenas 10 linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ENTIDADE: LUGAR (PAÍS)\n",
    "\n",
    "Alimenta a a tabela country_doc, da nossa base no mysql, fazendo interseção de dados da tabela countries com a tabela docs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "alimenta a a tabela person_doc, da nossa base no mysql.\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "count = 0\n",
    "#percentil = int(len(cursor.rowcount/100)\n",
    "\n",
    "pass_sshkey = getpass.getpass()\n",
    "pass_mysql = getpass.getpass()\n",
    "with SSHTunnelForwarder(('200.20.164.147', 22),\n",
    "                        ssh_private_key = \"C:/Users/marcelo.ribeiro/Dropbox/A-Marcelo/Educação-Trabalho/2016-CPDOC/Remoto/marcelo_priv_rsa\",\n",
    "                        #ssh_private_key = '/home/rsouza/.ssh/id_rsa',\n",
    "                        ssh_private_key_password = pass_sshkey,\n",
    "                        ssh_username=\"marcelobribeiro\",\n",
    "                        #ssh_username=\"rsouza\",\n",
    "                        remote_bind_address=('127.0.0.1', 3306)) as server:\n",
    "    \n",
    "    conn = pymysql.connect(host='localhost', \n",
    "                           port=server.local_bind_port, \n",
    "                           user='marcelobribeiro', \n",
    "                           #user='rsouza',\n",
    "                           passwd=pass_mysql,\n",
    "                           db='CPDOC_AS',\n",
    "                           use_unicode=True, \n",
    "                           charset=\"utf8\")\n",
    "    cur = conn.cursor()\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    insere dados na base mysql\n",
    "    captura documentos da tabela docs, transfere para a tabela topic-doc e insere dados de tópicos\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS country_doc\")\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS country_doc \n",
    "               (country_id VARBINARY(11), doc_id VARCHAR(31), person_count INT(11)\n",
    "               DEFAULT NULL)\n",
    "               ENGINE=MyISAM DEFAULT CHARSET='utf8';''')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
