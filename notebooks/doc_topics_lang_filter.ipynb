{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc_topics\n",
    "ESTABELECE RELAÇÕES ENTRE DOCUMENTOS E TÓPICOS NA BASE DE DADOS NO MYSQL. TRABALHAMOS COM O ACERVO **ANTONIO AZEREDO DA SILVEIRA, MINISTÉRIO DAS RELAÇÕES EXTERIORES**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "C:\\Anaconda3\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "C:\\Anaconda3\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "C:\\Anaconda3\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "C:\\Anaconda3\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "C:\\Anaconda3\\lib\\site-packages\\funcy\\decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import codecs\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from gensim import corpora, models, similarities #Latent Dirichlet Allocation implementation with Gensim\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import getpass\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = \"../outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n",
      "········\n"
     ]
    }
   ],
   "source": [
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "Seleciona textos da base mysql para fazer modelagem de tópicos\n",
    "NOTA: DEIXEI EM RAW PORQUE ESSA EXTRAÇÃO TORNA O CÓDIGO MUITO LENTO, MAS DEVE SER FEITO DESSA FORMA NO CPU DO RENATO\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "count = 0\n",
    "texts = []\n",
    "percentil = 10500/100\n",
    "pass_sshkey = getpass.getpass()\n",
    "pass_mysql = getpass.getpass()\n",
    "\n",
    "with SSHTunnelForwarder(('200.20.164.147', 22),\n",
    "                        ssh_private_key = \"C:/Users/marcelo.ribeiro/Dropbox/A-Marcelo/Educação-Trabalho/2016-CPDOC/Remoto/marcelo_priv_rsa\",\n",
    "                        #ssh_private_key = '/home/rsouza/.ssh/id_rsa',\n",
    "                        ssh_private_key_password = pass_sshkey,\n",
    "                        #ssh_private_key_password = input('Entre com a senha da chave privada'),\n",
    "                        ssh_username=\"marcelobribeiro\",\n",
    "                        #ssh_username=\"rsouza\",\n",
    "                        remote_bind_address=('127.0.0.1', 3306)) as server:\n",
    "    \n",
    "    conn = pymysql.connect(host='localhost', \n",
    "                           port=server.local_bind_port, \n",
    "                           user='marcelobribeiro', \n",
    "                           #user='rsouza',\n",
    "                           passwd=pass_mysql,\n",
    "                           #passwd=input('Entre com a senha do usuário no banco de dados'),\n",
    "                           db='CPDOC_AS',\n",
    "                           use_unicode=True, \n",
    "                           charset=\"utf8\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    captura documentos da tabela docs para posterior modelagem de tópicos\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    cur.execute(\"SELECT * FROM CPDOC_AS.docs WHERE main_language = 1\") # seleciona apenas textos majoritariamente em português    \n",
    "    row = cur.fetchone()\n",
    "                    \n",
    "    while row is not None:\n",
    "        count += 1\n",
    "        row = cur.fetchone()\n",
    "    \n",
    "        if count % percentil == 0: \n",
    "            clear_output()\n",
    "            print(int(count/percentil),'% done')\n",
    "                \n",
    "        text =  row[1]\n",
    "        text = text.split()\n",
    "        symbols = [x for x in string.punctuation]\n",
    "        text = [p for p in text if p not in symbols]\n",
    "        text = [p.strip(string.punctuation) for p in text]\n",
    "        text = [p for p in text if not p.isdigit()]\n",
    "        text = [p for p in text if len(p)>1]\n",
    "        texts.append(text)\n",
    "        \n",
    "        #if count == 3: break #amostra de apenas 3 linhas. No computador do Renato, não usar o break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "\n",
    "additional_words = ['mr','one', 'two', 'three', 'four', \n",
    "                    'five', 'um', 'dois', 'três', 'quatro', \n",
    "                    'cinco', 'janeiro', 'fevereiro', 'março', \n",
    "                    'abril', 'maio', 'junho', 'julho', 'agosto', \n",
    "                    'setembro', 'outubro', 'novembro', 'dezembro', \n",
    "                    'january', 'february', 'march', 'april', 'may', \n",
    "                    'june', 'july', 'august', 'september', \n",
    "                    'october', 'november', 'december', 'países', \n",
    "                    'ser', 'país', 'ainda', 'milhões', 'maior', \n",
    "                    'anos', 'grande', 'apenas', 'outros', 'pode', \n",
    "                    'parte', 'partes', 'item', 'vossa', 'nota', \n",
    "                    'havia', 'pt', 'vg', 'ptvg', 'eh', 'nr', 'hrs', \n",
    "                    'pais', 'parte', 'hoje', 'brasemb', 'ontem', \n",
    "                    'dia', 'countries', 'would', 'new', 'also', \n",
    "                    'must', 'draft', 'shall', 'item', 'page', \n",
    "                    'th', 'anos', 'ii', 'dias', 'poderá', 'caso', \n",
    "                    'casos', 'qualquer', 'ano', 'mil', 'pessoas', \n",
    "                    'único', 'única', 'únicos', 'únicas', 'índice', \n",
    "                    'expedido', 'co', 'mm', 'er', 'via', 'ww', 'ra', \n",
    "                    'ia', 'ca', 'nu', 'wa', 'aa', 'ms', 'dc', 'mmm', 'pa']\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english') + \\\n",
    "            nltk.corpus.stopwords.words('portuguese') + \\\n",
    "            nltk.corpus.stopwords.words('french') + \\\n",
    "            nltk.corpus.stopwords.words('spanish') + \\\n",
    "            additional_words\n",
    "\n",
    "stopwords = list(set(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "#%time texts = [[word for word in text] for text in texts]\n",
    "%time texts = [[word for word in text if word not in stopwords] for text in textos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "#print(len([word for word in texts[0] if word not in stopwords]))\n",
    "print(len(texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)\n",
    "#print(dictionary.token2id['']) #examina o id a partir do token\n",
    "#print(dictionary.id2token[0]) #examina o token a partir do id\n",
    "dictionary.filter_tokens(bad_ids=[0,]) #retira palavras a partir do id\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 668 ms\n"
     ]
    }
   ],
   "source": [
    "%time lda = models.LdaModel(corpus, num_topics=50, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*da + 0.003*grupo + 0.003*direitos + 0.003*humanos + 0.003*comunicações + 0.003*que + 0.003*por + 0.002*comissão + 0.002*no + 0.002*dos + 0.002*brasil + 0.002*ao + 0.002*foram + 0.002*se + 0.002*contra + 0.002*américa + 0.002*embaixador + 0.002*as + 0.002*membro + 0.002*discriminação'),\n",
       " (1,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (2,\n",
       "  '0.003*da + 0.003*grupo + 0.003*humanos + 0.003*no + 0.003*que + 0.003*dos + 0.003*comunicações + 0.003*contra + 0.003*comissão + 0.003*brasil + 0.003*foram + 0.003*direitos + 0.003*junto + 0.003*alegações + 0.003*as + 0.002*se + 0.002*ao + 0.002*realizada + 0.002*na + 0.002*membro'),\n",
       " (3,\n",
       "  '0.003*que + 0.003*da + 0.003*bolívia + 0.003*estados + 0.003*dos + 0.003*na + 0.003*unidos + 0.003*os + 0.002*não + 0.002*um + 0.002*seu + 0.002*americano + 0.002*relações + 0.002*boliviana + 0.002*assistência + 0.002*secretário + 0.002*todman + 0.002*às + 0.002*ao + 0.002*no'),\n",
       " (4,\n",
       "  '0.002*da + 0.002*no + 0.002*humanos + 0.002*comissão + 0.002*grupo + 0.002*que + 0.002*direitos + 0.002*brasil + 0.002*por + 0.002*ao + 0.002*comunicações + 0.002*as + 0.002*dos + 0.002*junto + 0.002*membro + 0.002*genebra + 0.002*alegações + 0.002*se + 0.002*na + 0.002*subcomissão'),\n",
       " (5,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (6,\n",
       "  '0.003*da + 0.003*que + 0.003*no + 0.003*unidos + 0.003*dos + 0.003*não + 0.003*humanos + 0.003*direitos + 0.003*grupo + 0.003*ao + 0.003*na + 0.003*bolívia + 0.003*estados + 0.003*um + 0.003*os + 0.003*por + 0.003*comunicações + 0.003*comissão + 0.003*as + 0.003*brasil'),\n",
       " (7,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (8,\n",
       "  '0.003*da + 0.003*que + 0.003*dos + 0.003*no + 0.003*unidos + 0.003*direitos + 0.003*humanos + 0.003*na + 0.003*grupo + 0.003*comunicações + 0.003*ao + 0.003*não + 0.003*comissão + 0.003*bolívia + 0.003*as + 0.003*estados + 0.003*por + 0.003*brasil + 0.003*os + 0.003*américa'),\n",
       " (9,\n",
       "  '0.002*que + 0.002*dos + 0.002*da + 0.002*unidos + 0.002*estados + 0.002*não + 0.002*todman + 0.002*seu + 0.002*bolívia + 0.002*na + 0.002*os + 0.002*boliviana + 0.002*ao + 0.002*das + 0.002*no + 0.002*secretário + 0.002*país + 0.002*americano + 0.002*relações + 0.002*exterior'),\n",
       " (10,\n",
       "  '0.002*da + 0.002*grupo + 0.002*humanos + 0.002*comunicações + 0.002*brasil + 0.002*contra + 0.002*no + 0.002*que + 0.002*comissão + 0.002*direitos + 0.002*ao + 0.002*dos + 0.002*alegações + 0.002*junto + 0.002*as + 0.002*por + 0.002*global + 0.002*foram + 0.002*américa + 0.002*genebra'),\n",
       " (11,\n",
       "  '0.057*global + 0.038*ministro + 0.038*exteriores + 0.038*estado + 0.019*suogeogunwwoo + 0.019*transcurso + 0.019*familia + 0.019*onu + 0.019*respeitosos + 0.019*cumprimentos + 0.019*telegrama + 0.019*et + 0.019*chanceler + 0.019*serie + 0.019*ereguan + 0.019*leqom + 0.019*data + 0.019*natalicia + 0.019*communications + 0.019*sr'),\n",
       " (12,\n",
       "  '0.004*da + 0.004*que + 0.004*no + 0.003*dos + 0.003*unidos + 0.003*direitos + 0.003*ao + 0.003*na + 0.003*humanos + 0.003*por + 0.003*um + 0.003*grupo + 0.003*os + 0.003*não + 0.003*comissão + 0.003*estados + 0.003*comunicações + 0.003*as + 0.003*américa + 0.003*se'),\n",
       " (13,\n",
       "  '0.003*da + 0.003*que + 0.003*no + 0.003*dos + 0.003*humanos + 0.003*unidos + 0.003*direitos + 0.003*grupo + 0.003*estados + 0.003*na + 0.003*não + 0.003*ao + 0.003*comissão + 0.003*as + 0.003*comunicações + 0.003*por + 0.003*brasil + 0.003*os + 0.003*se + 0.003*seu'),\n",
       " (14,\n",
       "  '0.040*da + 0.021*no + 0.021*grupo + 0.018*direitos + 0.018*humanos + 0.018*que + 0.015*dos + 0.015*brasil + 0.015*comissão + 0.015*por + 0.015*comunicações + 0.012*contra + 0.012*foram + 0.012*ao + 0.012*as + 0.009*subcomissão + 0.009*junto + 0.009*américa + 0.009*membro + 0.009*genebra'),\n",
       " (15,\n",
       "  '0.003*da + 0.003*humanos + 0.003*no + 0.003*direitos + 0.003*grupo + 0.003*comissão + 0.003*por + 0.003*dos + 0.003*contra + 0.003*comunicações + 0.002*que + 0.002*subcomissão + 0.002*brasil + 0.002*as + 0.002*ao + 0.002*na + 0.002*américa + 0.002*junto + 0.002*foram + 0.002*genebra'),\n",
       " (16,\n",
       "  '0.003*da + 0.003*grupo + 0.003*no + 0.003*humanos + 0.003*que + 0.003*direitos + 0.003*por + 0.003*foram + 0.003*brasil + 0.003*as + 0.003*comissão + 0.003*comunicações + 0.003*alegações + 0.003*dos + 0.003*contra + 0.003*ao + 0.003*setembro + 0.003*na + 0.003*subcomissão + 0.003*américa'),\n",
       " (17,\n",
       "  '0.003*global + 0.003*estado + 0.003*exteriores + 0.003*ministro + 0.003*americo + 0.003*retransmito + 0.003*recebido + 0.003*nova + 0.003*lopes + 0.003*york + 0.003*communicaiions + 0.003*particular + 0.003*communic + 0.003*eqoyg + 0.003*retransmissão + 0.003*suonesyunwuuog + 0.003*suoueogunwwoo + 0.003*25/9/74 + 0.003*em/23/9/74 + 0.003*conhecimento'),\n",
       " (18,\n",
       "  '0.003*da + 0.003*que + 0.003*bolívia + 0.003*unidos + 0.003*na + 0.003*dos + 0.003*não + 0.002*estados + 0.002*os + 0.002*no + 0.002*boliviana + 0.002*relações + 0.002*seu + 0.002*um + 0.002*todman + 0.002*das + 0.002*ao + 0.002*secretário + 0.002*país + 0.002*americano'),\n",
       " (19,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (20,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (21,\n",
       "  '0.003*da + 0.003*direitos + 0.002*por + 0.002*grupo + 0.002*no + 0.002*humanos + 0.002*que + 0.002*comunicações + 0.002*ao + 0.002*brasil + 0.002*contra + 0.002*comissão + 0.002*foram + 0.002*as + 0.002*dos + 0.002*na + 0.002*junto + 0.002*discriminação + 0.002*genebra + 0.002*se'),\n",
       " (22,\n",
       "  '0.003*que + 0.003*dos + 0.003*unidos + 0.003*da + 0.003*bolívia + 0.003*estados + 0.003*na + 0.003*os + 0.003*todman + 0.003*relações + 0.003*país + 0.003*boliviana + 0.003*seu + 0.003*ao + 0.003*um + 0.003*no + 0.003*não + 0.003*das + 0.003*congresso + 0.002*americano'),\n",
       " (23,\n",
       "  '0.003*que + 0.003*da + 0.003*dos + 0.003*unidos + 0.003*bolívia + 0.003*estados + 0.003*os + 0.003*não + 0.003*secretário + 0.003*na + 0.003*ao + 0.003*americano + 0.003*relações + 0.003*seu + 0.003*um + 0.003*uma + 0.003*país + 0.003*exterior + 0.003*boliviana + 0.003*embora'),\n",
       " (24,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (25,\n",
       "  '0.003*da + 0.003*que + 0.003*dos + 0.002*na + 0.002*estados + 0.002*no + 0.002*ao + 0.002*os + 0.002*unidos + 0.002*bolívia + 0.002*humanos + 0.002*não + 0.002*direitos + 0.002*um + 0.002*seu + 0.002*relações + 0.002*das + 0.002*comunicações + 0.002*sobre + 0.002*todman'),\n",
       " (26,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (27,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (28,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (29,\n",
       "  '0.004*que + 0.003*unidos + 0.003*da + 0.003*dos + 0.003*estados + 0.003*não + 0.003*os + 0.003*bolívia + 0.003*das + 0.003*na + 0.003*boliviana + 0.003*americano + 0.003*seu + 0.003*país + 0.003*todman + 0.003*no + 0.003*relações + 0.003*secretário + 0.003*Kissinger + 0.003*uma'),\n",
       " (30,\n",
       "  '0.030*que + 0.023*unidos + 0.020*da + 0.020*dos + 0.017*estados + 0.017*bolívia + 0.013*na + 0.013*os + 0.013*não + 0.010*um + 0.010*secretário + 0.010*ao + 0.010*no + 0.010*das + 0.010*seu + 0.010*relações + 0.010*americano + 0.010*país + 0.010*todman + 0.010*boliviana'),\n",
       " (31,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (32,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (33,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (34,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (35,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora'),\n",
       " (36,\n",
       "  '0.005*da + 0.004*grupo + 0.003*que + 0.003*comunicações + 0.003*no + 0.003*humanos + 0.003*direitos + 0.003*brasil + 0.003*as + 0.003*foram + 0.003*por + 0.003*dos + 0.003*ao + 0.003*comissão + 0.003*contra + 0.003*se + 0.003*membro + 0.003*alegações + 0.003*américa + 0.003*na'),\n",
       " (37,\n",
       "  '0.004*que + 0.003*dos + 0.003*da + 0.003*bolívia + 0.003*unidos + 0.003*não + 0.003*estados + 0.003*na + 0.003*ao + 0.003*boliviana + 0.003*os + 0.003*no + 0.003*americano + 0.003*um + 0.003*todman + 0.003*secretário + 0.003*seu + 0.003*país + 0.003*das + 0.003*problemas'),\n",
       " (38,\n",
       "  '0.003*que + 0.003*da + 0.003*unidos + 0.003*estados + 0.003*dos + 0.002*não + 0.002*bolívia + 0.002*na + 0.002*secretário + 0.002*um + 0.002*das + 0.002*todman + 0.002*ao + 0.002*no + 0.002*os + 0.002*americano + 0.002*país + 0.002*seu + 0.002*pela + 0.002*congresso'),\n",
       " (39,\n",
       "  '0.002*pas + 0.002*lizou + 0.002*julho + 0.002*pela + 0.002*natalicia + 0.002*pronunciou + 0.002*referente + 0.002*sendo + 0.002*precederam + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*tocante + 0.002*vista + 0.002*interesses + 0.002*foi + 0.002*apreço + 0.002*aos + 0.002*ação + 0.002*embora')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics(-1, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.003*da + 0.003*grupo + 0.003*direitos + 0.003*humanos + 0.003*comunicações + 0.003*que + 0.003*por + 0.002*comissão + 0.002*no + 0.002*dos'),\n",
       " (1,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (2,\n",
       "  '0.003*da + 0.003*grupo + 0.003*humanos + 0.003*no + 0.003*que + 0.003*dos + 0.003*comunicações + 0.003*contra + 0.003*comissão + 0.003*brasil'),\n",
       " (3,\n",
       "  '0.003*que + 0.003*da + 0.003*bolívia + 0.003*estados + 0.003*dos + 0.003*na + 0.003*unidos + 0.003*os + 0.002*não + 0.002*um'),\n",
       " (4,\n",
       "  '0.002*da + 0.002*no + 0.002*humanos + 0.002*comissão + 0.002*grupo + 0.002*que + 0.002*direitos + 0.002*brasil + 0.002*por + 0.002*ao'),\n",
       " (5,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (6,\n",
       "  '0.003*da + 0.003*que + 0.003*no + 0.003*unidos + 0.003*dos + 0.003*não + 0.003*humanos + 0.003*direitos + 0.003*grupo + 0.003*ao'),\n",
       " (7,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (8,\n",
       "  '0.003*da + 0.003*que + 0.003*dos + 0.003*no + 0.003*unidos + 0.003*direitos + 0.003*humanos + 0.003*na + 0.003*grupo + 0.003*comunicações'),\n",
       " (9,\n",
       "  '0.002*que + 0.002*dos + 0.002*da + 0.002*unidos + 0.002*estados + 0.002*não + 0.002*todman + 0.002*seu + 0.002*bolívia + 0.002*na'),\n",
       " (10,\n",
       "  '0.002*da + 0.002*grupo + 0.002*humanos + 0.002*comunicações + 0.002*brasil + 0.002*contra + 0.002*no + 0.002*que + 0.002*comissão + 0.002*direitos'),\n",
       " (11,\n",
       "  '0.057*global + 0.038*ministro + 0.038*exteriores + 0.038*estado + 0.019*suogeogunwwoo + 0.019*transcurso + 0.019*familia + 0.019*onu + 0.019*respeitosos + 0.019*cumprimentos'),\n",
       " (12,\n",
       "  '0.004*da + 0.004*que + 0.004*no + 0.003*dos + 0.003*unidos + 0.003*direitos + 0.003*ao + 0.003*na + 0.003*humanos + 0.003*por'),\n",
       " (13,\n",
       "  '0.003*da + 0.003*que + 0.003*no + 0.003*dos + 0.003*humanos + 0.003*unidos + 0.003*direitos + 0.003*grupo + 0.003*estados + 0.003*na'),\n",
       " (14,\n",
       "  '0.040*da + 0.021*no + 0.021*grupo + 0.018*direitos + 0.018*humanos + 0.018*que + 0.015*dos + 0.015*brasil + 0.015*comissão + 0.015*por'),\n",
       " (15,\n",
       "  '0.003*da + 0.003*humanos + 0.003*no + 0.003*direitos + 0.003*grupo + 0.003*comissão + 0.003*por + 0.003*dos + 0.003*contra + 0.003*comunicações'),\n",
       " (16,\n",
       "  '0.003*da + 0.003*grupo + 0.003*no + 0.003*humanos + 0.003*que + 0.003*direitos + 0.003*por + 0.003*foram + 0.003*brasil + 0.003*as'),\n",
       " (17,\n",
       "  '0.003*global + 0.003*estado + 0.003*exteriores + 0.003*ministro + 0.003*americo + 0.003*retransmito + 0.003*recebido + 0.003*nova + 0.003*lopes + 0.003*york'),\n",
       " (18,\n",
       "  '0.003*da + 0.003*que + 0.003*bolívia + 0.003*unidos + 0.003*na + 0.003*dos + 0.003*não + 0.002*estados + 0.002*os + 0.002*no'),\n",
       " (19,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (20,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (21,\n",
       "  '0.003*da + 0.003*direitos + 0.002*por + 0.002*grupo + 0.002*no + 0.002*humanos + 0.002*que + 0.002*comunicações + 0.002*ao + 0.002*brasil'),\n",
       " (22,\n",
       "  '0.003*que + 0.003*dos + 0.003*unidos + 0.003*da + 0.003*bolívia + 0.003*estados + 0.003*na + 0.003*os + 0.003*todman + 0.003*relações'),\n",
       " (23,\n",
       "  '0.003*que + 0.003*da + 0.003*dos + 0.003*unidos + 0.003*bolívia + 0.003*estados + 0.003*os + 0.003*não + 0.003*secretário + 0.003*na'),\n",
       " (24,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (25,\n",
       "  '0.003*da + 0.003*que + 0.003*dos + 0.002*na + 0.002*estados + 0.002*no + 0.002*ao + 0.002*os + 0.002*unidos + 0.002*bolívia'),\n",
       " (26,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (27,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (28,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (29,\n",
       "  '0.004*que + 0.003*unidos + 0.003*da + 0.003*dos + 0.003*estados + 0.003*não + 0.003*os + 0.003*bolívia + 0.003*das + 0.003*na'),\n",
       " (30,\n",
       "  '0.030*que + 0.023*unidos + 0.020*da + 0.020*dos + 0.017*estados + 0.017*bolívia + 0.013*na + 0.013*os + 0.013*não + 0.010*um'),\n",
       " (31,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (32,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (33,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (34,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (35,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses'),\n",
       " (36,\n",
       "  '0.005*da + 0.004*grupo + 0.003*que + 0.003*comunicações + 0.003*no + 0.003*humanos + 0.003*direitos + 0.003*brasil + 0.003*as + 0.003*foram'),\n",
       " (37,\n",
       "  '0.004*que + 0.003*dos + 0.003*da + 0.003*bolívia + 0.003*unidos + 0.003*não + 0.003*estados + 0.003*na + 0.003*ao + 0.003*boliviana'),\n",
       " (38,\n",
       "  '0.003*que + 0.003*da + 0.003*unidos + 0.003*estados + 0.003*dos + 0.002*não + 0.002*bolívia + 0.002*na + 0.002*secretário + 0.002*um'),\n",
       " (39,\n",
       "  '0.002*tocante + 0.002*vista + 0.002*afirmara + 0.002*beverly + 0.002*respeitosos + 0.002*pas + 0.002*apreço + 0.002*foi + 0.002*aos + 0.002*interesses')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.show_topics(num_topics=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34,\n",
       " [('pas', 0.0024213075060532689),\n",
       "  ('lizou', 0.0024213075060532689),\n",
       "  ('julho', 0.0024213075060532689),\n",
       "  ('pela', 0.0024213075060532689),\n",
       "  ('natalicia', 0.0024213075060532689),\n",
       "  ('pronunciou', 0.0024213075060532689),\n",
       "  ('referente', 0.0024213075060532689),\n",
       "  ('sendo', 0.0024213075060532689),\n",
       "  ('precederam', 0.0024213075060532689),\n",
       "  ('afirmara', 0.0024213075060532689),\n",
       "  ('beverly', 0.0024213075060532689),\n",
       "  ('respeitosos', 0.0024213075060532689),\n",
       "  ('tocante', 0.0024213075060532689),\n",
       "  ('vista', 0.0024213075060532689),\n",
       "  ('interesses', 0.0024213075060532689),\n",
       "  ('foi', 0.0024213075060532689),\n",
       "  ('apreço', 0.0024213075060532689),\n",
       "  ('aos', 0.0024213075060532689),\n",
       "  ('ação', 0.0024213075060532689),\n",
       "  ('embora', 0.0024213075060532689)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_matrix = lda.show_topics(formatted=False, num_words=20, num_topics=-1)\n",
    "topics_matrix[34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando a distribuição de tópicos para um novo documento:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gera a distribuição de tópicos para um novo documento\n",
    "Alimenta a base mysql com dados de score (relação) entre tópicos e documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "#percentil = int(len(cursor.rowcount/100)\n",
    "\n",
    "pass_sshkey = getpass.getpass()\n",
    "pass_mysql = getpass.getpass()\n",
    "with SSHTunnelForwarder(('200.20.164.147', 22),\n",
    "                        ssh_private_key = \"C:/Users/marcelo.ribeiro/Dropbox/A-Marcelo/Educação-Trabalho/2016-CPDOC/Remoto/marcelo_priv_rsa\",\n",
    "                        #ssh_private_key = '/home/rsouza/.ssh/id_rsa',\n",
    "                        ssh_private_key_password = pass_sshkey,\n",
    "                        ssh_username=\"marcelobribeiro\",\n",
    "                        #ssh_username=\"rsouza\",\n",
    "                        remote_bind_address=('127.0.0.1', 3306)) as server:\n",
    "    \n",
    "    conn = pymysql.connect(host='localhost', \n",
    "                           port=server.local_bind_port, \n",
    "                           user='marcelobribeiro', \n",
    "                           #user='rsouza',\n",
    "                           passwd=pass_mysql,\n",
    "                           db='CPDOC_AS',\n",
    "                           use_unicode=True, \n",
    "                           charset=\"utf8\")\n",
    "    cur = conn.cursor()\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    insere dados na base mysql\n",
    "    captura documentos da tabela docs, transfere para a tabela topic-doc e insere dados de tópicos\n",
    "    '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS topic_doc_lang_filter\")\n",
    "    cur.execute('''CREATE TABLE IF NOT EXISTS topic_doc_lang_filter \n",
    "               (doc_id VARCHAR(31), topic_id smallint(6), topic_score FLOAT\n",
    "               DEFAULT NULL)\n",
    "               ENGINE=MyISAM DEFAULT CHARSET='utf8';''')\n",
    "\n",
    "    cur.execute(\"SELECT id,body FROM CPDOC_AS.docs\")\n",
    "    data = cur.fetchall()\n",
    "    for row in data:\n",
    "        count += 1 # for break event\n",
    "        if row is None: break\n",
    "        text =  row[1]\n",
    "        text = text.split()\n",
    "        text_bow = dictionary.doc2bow(text)\n",
    "        print(lda[text_bow])\n",
    "        score_list = lda[text_bow]\n",
    "        doc_id = row[0]\n",
    "        for score in score_list:\n",
    "            topic_id = str(score[0])\n",
    "            topic_score = str(score[1])\n",
    "            query = \"INSERT INTO topic_doc VALUES (%s, %s, %s)\"\n",
    "            cur.execute(query, (doc_id, topic_id, topic_score))\n",
    "        print(doc_id, topic_id, topic_score)   \n",
    "        cur.execute(\"ALTER TABLE CPDOC_AS.topic_doc ORDER BY topic_id ASC, topic_score DESC\")\n",
    "        \n",
    "        #if count == 10: break #amostra de apenas 10 linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizando os tópicos com o PyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://cran.r-project.org/web/packages/LDAvis/vignettes/details.pdf\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ldavis = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.save_html(data_ldavis, os.path.join(outputs,'pyldavis_langfilter_output.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
